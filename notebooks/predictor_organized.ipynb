{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # NFL Game Prediction Model\n",
    "\n",
    "\n",
    "\n",
    " This notebook builds a machine learning model to predict NFL game outcomes using historical performance data.\n",
    "\n",
    "\n",
    "\n",
    " ## Overview\n",
    "\n",
    " - **Data Source**: nflreadrpy library (2021-2025 seasons)\n",
    "\n",
    " - **Model**: Logistic Regression with feature selection\n",
    "\n",
    " - **Features**: EWMA (Exponentially Weighted Moving Average) team statistics\n",
    "\n",
    " - **Target**: Home team win/loss\n",
    "\n",
    "\n",
    "\n",
    " ## Table of Contents\n",
    "\n",
    " 1. [Setup & Imports](#1-setup--imports)\n",
    "\n",
    " 2. [Load Game Schedules](#2-load-game-schedules)\n",
    "\n",
    " 3. [Load & Engineer Team Stats](#3-load--engineer-team-stats)\n",
    "\n",
    " 4. [Calculate EWMA Features](#4-calculate-ewma-features)\n",
    "\n",
    " 5. [Merge Stats to Games](#5-merge-stats-to-games)\n",
    "\n",
    " 6. [Feature Selection](#6-feature-selection)\n",
    "\n",
    " 7. [Train Final Model](#7-train-final-model)\n",
    "\n",
    " 8. [Save Model & Artifacts](#8-save-model--artifacts)\n",
    "\n",
    " 9. [Make Predictions](#9-make-predictions)\n",
    "\n",
    " 10. [Visualize Results](#10-visualize-results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 1. Setup & Imports\n",
    "\n",
    "\n",
    "\n",
    " Import required libraries and create directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as the Python Environment 'nfl_predictor (Python -1.-1.-1)' is no longer available. Consider selecting another kernel or refreshing the list of Python Environments."
     ]
    }
   ],
   "source": [
    "import nflreadpy as nfl\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 2. Load Game Schedules\n",
    "\n",
    "\n",
    "\n",
    " Load NFL schedule data from 2021-2025 seasons and filter for completed regular season games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading schedules...\")\n",
    "schedule = nfl.load_schedules([2021, 2022, 2023, 2024, 2025]).to_pandas()\n",
    "\n",
    "# Filter for completed regular season games\n",
    "games = schedule[\n",
    "    (schedule['game_type'] == 'REG') &  # Regular season only\n",
    "    (schedule['home_score'].notna()) &  # Game has been played\n",
    "    (schedule['away_score'].notna())\n",
    "].copy()\n",
    "\n",
    "# Create target variable\n",
    "games['home_win'] = (games['home_score'] > games['away_score']).astype(int)\n",
    "\n",
    "print(f\" Loaded {len(games):,} completed games\")\n",
    "print(f\"   Seasons: {games['season'].min()} - {games['season'].max()}\")\n",
    "print(f\"   Home team wins: {games['home_win'].sum():,} ({games['home_win'].mean():.1%})\")\n",
    "\n",
    "# Preview data\n",
    "games[['season', 'week', 'away_team', 'home_team', 'away_score', 'home_score', 'home_win']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 3. Load & Engineer Team Stats\n",
    "\n",
    "\n",
    "\n",
    " Load team-level statistics and create derived features:\n",
    "\n",
    " - **Turnovers Offense**: Interceptions + fumbles lost\n",
    "\n",
    " - **Turnovers Defense**: Interceptions + fumbles recovered\n",
    "\n",
    " - **Turnover Margin**: Defense turnovers - Offense turnovers\n",
    "\n",
    " - **Completion Percentage**: Completions / Attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading team statistics...\")\n",
    "team_stats = nfl.load_team_stats([2021, 2022, 2023, 2024, 2025]).to_pandas()\n",
    "\n",
    "print(f\"Loaded {len(team_stats):,} team game records\")\n",
    "print(f\"   Teams: {team_stats['team'].nunique()}\")\n",
    "print(f\"   Columns: {len(team_stats.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating derived features...\")\n",
    "\n",
    "# Offensive turnovers\n",
    "team_stats['turnovers_offense'] = (\n",
    "    team_stats['passing_interceptions'] + \n",
    "    team_stats['sack_fumbles_lost'] +\n",
    "    team_stats['rushing_fumbles_lost'] +\n",
    "    team_stats['receiving_fumbles_lost']\n",
    ")\n",
    "\n",
    "# Defensive turnovers\n",
    "team_stats['turnovers_defense'] = (\n",
    "    team_stats['def_interceptions'] +\n",
    "    team_stats['def_fumbles']\n",
    ")\n",
    "\n",
    "# Turnover margin\n",
    "team_stats['turnover_margin'] = (\n",
    "    team_stats['turnovers_defense'] - \n",
    "    team_stats['turnovers_offense']\n",
    ")\n",
    "\n",
    "# Completion percentage\n",
    "team_stats['completion_pct'] = (\n",
    "    team_stats['completions'] / team_stats['attempts']\n",
    ")\n",
    "\n",
    "print(\" Created 4 derived features\")\n",
    "\n",
    "# Preview new features\n",
    "team_stats[['team', 'week', 'turnovers_offense', 'turnovers_defense', \n",
    "            'turnover_margin', 'completion_pct']].head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 4. Calculate EWMA Features\n",
    "\n",
    "\n",
    "\n",
    " Calculate Exponentially Weighted Moving Averages (EWMA) for each feature.\n",
    "\n",
    "\n",
    "\n",
    " **Why EWMA?**\n",
    "\n",
    " - Emphasizes recent performance over older games\n",
    "\n",
    " - Alpha = 0.4 means recent games have ~2.5x more weight than games 5 weeks ago\n",
    "\n",
    " - Captures team momentum and current form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features to use\n",
    "independent_variables = [\n",
    "    'completions',\n",
    "    'passing_yards',\n",
    "    'passing_tds',\n",
    "    'rushing_yards',\n",
    "    'sacks_suffered',\n",
    "    'rushing_tds',\n",
    "    'completion_pct',\n",
    "    'turnovers_offense',\n",
    "    'turnovers_defense',\n",
    "    'turnover_margin',\n",
    "    'def_tackles_for_loss',\n",
    "    'penalty_yards',\n",
    "    'fg_pct',\n",
    "    'pat_pct',\n",
    "]\n",
    "\n",
    "print(f\"Calculating EWMA for {len(independent_variables)} features...\")\n",
    "print(\"Alpha = 0.4 (gives more weight to recent games)\")\n",
    "\n",
    "# Calculate EWMA for each feature\n",
    "for var in independent_variables:\n",
    "    team_stats[f'{var}_ewma'] = team_stats.groupby(['team', 'season'])[var].transform(\n",
    "        lambda x: x.ewm(alpha=0.4, adjust=False).mean()\n",
    "    )\n",
    "\n",
    "# Select columns to keep\n",
    "ewma_cols = [f'{col}_ewma' for col in independent_variables]\n",
    "keep_cols = ['season', 'week', 'team', 'opponent_team'] + ewma_cols\n",
    "df_filtered = team_stats[keep_cols]\n",
    "\n",
    "# Save processed data\n",
    "df_filtered.to_csv('../data/df_clean.csv', index=False)\n",
    "\n",
    "print(f\" Created {len(ewma_cols)} EWMA features\")\n",
    "print(f\" Saved to data/df_clean.csv\")\n",
    "\n",
    "# Preview EWMA features\n",
    "df_filtered.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 5. Merge Stats to Games\n",
    "\n",
    "\n",
    "\n",
    " Merge EWMA statistics for both home and away teams to each game, then create difference features.\n",
    "\n",
    "\n",
    "\n",
    " **Difference Features**: Home stat - Away stat\n",
    "\n",
    " - Positive value = Home team advantage in that stat\n",
    "\n",
    " - Negative value = Away team advantage in that stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Merging home team stats...\")\n",
    "# Prepare home stats\n",
    "home_stats = df_filtered[['season', 'week', 'team'] + ewma_cols].copy()\n",
    "home_stats.columns = ['season', 'week', 'home_team'] + [f'home_{col}' for col in ewma_cols]\n",
    "\n",
    "print(\"Merging away team stats...\")\n",
    "# Prepare away stats\n",
    "away_stats = df_filtered[['season', 'week', 'team'] + ewma_cols].copy()\n",
    "away_stats.columns = ['season', 'week', 'away_team'] + [f'away_{col}' for col in ewma_cols]\n",
    "\n",
    "# Merge both to games\n",
    "games_with_stats = games.merge(\n",
    "    home_stats,\n",
    "    on=['season', 'week', 'home_team'],\n",
    "    how='left'\n",
    ").merge(\n",
    "    away_stats,\n",
    "    on=['season', 'week', 'away_team'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\" Merged stats to {len(games_with_stats):,} games\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Creating difference features (Home - Away)...\")\n",
    "\n",
    "feature_columns = []\n",
    "for col in ewma_cols:\n",
    "    diff_col = f'{col}_diff'\n",
    "    games_with_stats[diff_col] = (\n",
    "        games_with_stats[f'home_{col}'] - games_with_stats[f'away_{col}']\n",
    "    )\n",
    "    feature_columns.append(diff_col)\n",
    "\n",
    "print(f\" Created {len(feature_columns)} difference features\")\n",
    "\n",
    "# Save merged data\n",
    "games_with_stats.to_csv('../data/games_with_stats.csv', index=False)\n",
    "print(\" Saved to data/games_with_stats.csv\")\n",
    "\n",
    "# Preview difference features\n",
    "display_cols = ['season', 'week', 'home_team', 'away_team', 'home_win'] + feature_columns\n",
    "games_with_stats[display_cols].head()\n",
    "games_with_stats = games_with_stats.fillna({'pat_pct_ewma_diff': 0, 'fg_pct_ewma_diff': 0})\n",
    "print(f\"total na values: {games_with_stats[display_cols].isna().sum().sum()}\")\n",
    "games_with_stats[display_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 6. Feature Selection\n",
    "\n",
    "\n",
    "\n",
    " Use Random Forest to identify the most important features for prediction.\n",
    "\n",
    "\n",
    "\n",
    " This helps us:\n",
    "\n",
    " - Reduce model complexity\n",
    "\n",
    " - Improve interpretability\n",
    "\n",
    " - Potentially improve generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Splitting data into train/test sets...\")\n",
    "print(f\"  Training: Seasons 2021-2024\")\n",
    "print(f\"  Testing: Season 2025\")\n",
    "\n",
    "# Split by season\n",
    "train_data = games_with_stats[games_with_stats['season'] < 2025]\n",
    "test_data = games_with_stats[games_with_stats['season'] == 2025]\n",
    "\n",
    "X_train = train_data[feature_columns]\n",
    "y_train = train_data['home_win']\n",
    "\n",
    "X_test = test_data[feature_columns]\n",
    "y_test = test_data['home_win']\n",
    "\n",
    "print(f\"\\n Training set: {len(X_train):,} games\")\n",
    "print(f\" Testing set: {len(X_test):,} games\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining Random Forest for feature selection...\")\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200, \n",
    "    random_state=67, \n",
    "    max_depth=20, \n",
    "    min_samples_split=20,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(f\" Random Forest trained\")\n",
    "print(f\"   Training accuracy: {rf_model.score(X_train, y_train):.4f}\")\n",
    "print(f\"   Testing accuracy: {rf_model.score(X_test, y_test):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCalculating feature importance...\")\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "top_features = feature_importance.head(10)\n",
    "feature_list = top_features['feature'].to_list()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TOP 10 MOST IMPORTANT FEATURES\")\n",
    "print(f\"{'='*60}\")\n",
    "for i, row in top_features.iterrows():\n",
    "    print(f\"{i+1:2d}. {row['feature']:40s} {row['importance']:.4f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Save feature importance\n",
    "feature_importance.to_csv('../outputs/feature_importance.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPlotting feature importance...\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(top_features)), top_features['importance'], color='steelblue')\n",
    "plt.yticks(range(len(top_features)), top_features['feature'].to_list())\n",
    "plt.xlabel('Importance', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Feature', fontsize=12, fontweight='bold')\n",
    "plt.title('Top 10 Feature Importance', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\" Plot saved to outputs/feature_importance.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 7. Train Final Model\n",
    "\n",
    "\n",
    "\n",
    " Train a Logistic Regression model using only the top 10 most important features.\n",
    "\n",
    "\n",
    "\n",
    " **Why Logistic Regression?**\n",
    "\n",
    " - Fast and interpretable\n",
    "\n",
    " - Outputs probabilities (not just predictions)\n",
    "\n",
    " - Works well with scaled features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Preparing data with selected features...\")\n",
    "\n",
    "# Select top features\n",
    "X_train_selected = train_data[feature_list]\n",
    "X_test_selected = test_data[feature_list]\n",
    "\n",
    "print(f\"Using {len(feature_list)} features:\")\n",
    "for feat in feature_list:\n",
    "    print(f\"  - {feat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nScaling features...\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_selected)\n",
    "X_test_scaled = scaler.transform(X_test_selected)\n",
    "\n",
    "print(\" Features scaled (mean=0, std=1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining Logistic Regression model...\")\n",
    "\n",
    "model = LogisticRegression(random_state=41, max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate\n",
    "train_score = model.score(X_train_scaled, y_train)\n",
    "test_score = model.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MODEL PERFORMANCE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Training Accuracy:  {train_score:.4f} ({train_score:.1%})\")\n",
    "print(f\"Testing Accuracy:   {test_score:.4f} ({test_score:.1%})\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Get predictions and probabilities\n",
    "y_pred_train = model.predict(X_train_scaled)\n",
    "y_pred_test = model.predict(X_test_scaled)\n",
    "y_prob_train = model.predict_proba(X_train_scaled)[:, 1]\n",
    "y_prob_test = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "print(\"\\n Model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 8. Save Model & Artifacts\n",
    "\n",
    "\n",
    "\n",
    " Save the trained model, scaler, and feature list for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Saving model and artifacts...\")\n",
    "\n",
    "# Save model\n",
    "with open('../models/finalized_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "print(\"Model saved to models/finalized_model.pkl\")\n",
    "\n",
    "# Save scaler  \n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "print(\"Scaler saved to models/scaler.pkl\")\n",
    "\n",
    "# Save feature list\n",
    "with open('../models/feature_list.pkl', 'wb') as f:\n",
    "    pickle.dump(feature_list, f)\n",
    "print(\"Feature list saved to models/feature_list.pkl\")\n",
    "\n",
    "# Save most recent stats for predictions\n",
    "most_recent_stats = df_filtered.sort_values(['team', 'season', 'week']).groupby('team').last().reset_index()\n",
    "most_recent_stats.to_csv('../data/most_recent_stats1.csv', index=False)\n",
    "print(\"Most recent stats saved to data/most_recent_stats1.csv\")\n",
    "\n",
    "print(\"\\n All artifacts saved!\")\n",
    "most_recent_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 9. Make Predictions\n",
    "\n",
    "- Compare model results to Vegas game odds\n",
    "\n",
    "- Use the trained model to predict outcomes for upcoming games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Getting current week and season...\")\n",
    "\n",
    "current_week = nfl.get_current_week()\n",
    "current_season = nfl.get_current_season()\n",
    "\n",
    "print(f\"Current: Week {current_week}, {current_season} Season\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nLoading games for Week {current_week}...\")\n",
    "\n",
    "week_games = schedule[\n",
    "    (schedule['week'] == current_week) & \n",
    "    (schedule['season'] == current_season)\n",
    "]\n",
    "\n",
    "print(f\"Found {len(week_games)} games\")\n",
    "\n",
    "if len(week_games) == 0:\n",
    "    print(\" No games found for current week\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nLoading Vegas odds for Week {current_week}\")\n",
    "\n",
    "vegas_lines = schedule[(schedule['season'] == current_season) & \n",
    "                       (schedule['week'] == current_week)][['game_id', 'away_moneyline', 'home_moneyline']]\n",
    "print(f\"Found vegas odds\")\n",
    "\n",
    "if len(week_games) ==0:\n",
    "    print(\"No games found for current week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(week_games) > 0:\n",
    "    print(\"\\nPreparing prediction data...\")\n",
    "    \n",
    "    # Merge home team stats\n",
    "    df_matchups = week_games[['game_id', 'away_team', 'home_team', 'gameday']].merge(\n",
    "        most_recent_stats[keep_cols],\n",
    "        left_on='home_team',\n",
    "        right_on='team',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    stats_to_rename = [col for col in keep_cols if col != 'team']\n",
    "    df_matchups = df_matchups.rename(columns={col: f\"{col}_home\" for col in stats_to_rename})\n",
    "    \n",
    "    # Merge away team stats\n",
    "    df_matchups = df_matchups.merge(\n",
    "        most_recent_stats[keep_cols],\n",
    "        left_on='away_team',\n",
    "        right_on='team',\n",
    "        how='left',\n",
    "        suffixes=(\"\", \"_away\")\n",
    "    )\n",
    "    \n",
    "    df_matchups = df_matchups.rename(columns={\n",
    "        col: f\"{col}_away\" for col in stats_to_rename if col in df_matchups.columns\n",
    "    })\n",
    "    \n",
    "    # Create difference features\n",
    "    for stat in ewma_cols:\n",
    "        diff_col = f\"{stat}_diff\"\n",
    "        df_matchups[diff_col] = df_matchups[f\"{stat}_home\"] - df_matchups[f\"{stat}_away\"]\n",
    "    \n",
    "    print(\" Prediction data prepared\")\n",
    "    \n",
    "    # Make predictions\n",
    "    X_pred = df_matchups[feature_list]\n",
    "    X_pred_scaled = scaler.transform(X_pred)\n",
    "    win_probs = model.predict_proba(X_pred_scaled)[:, 1]\n",
    "\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results = pd.DataFrame({\n",
    "        'game_id': df_matchups['game_id'],\n",
    "        'matchup': df_matchups['away_team'] + [' @ '] + df_matchups['home_team'],\n",
    "        'away_team': df_matchups['away_team'],\n",
    "        'home_team': df_matchups['home_team'],\n",
    "        'game_date': df_matchups['gameday'],\n",
    "        'home_win_prob': win_probs,\n",
    "        'away_win_prob': 1 - win_probs\n",
    "    })\n",
    "    \n",
    "    # Add predicted winner\n",
    "    results['predicted_winner'] = results.apply(\n",
    "        lambda row: row['home_team'] if row['home_win_prob'] > 0.5 else row['away_team'],\n",
    "        axis=1\n",
    "    )\n",
    "    results['confidence'] = results[['home_win_prob', 'away_win_prob']].max(axis=1)\n",
    "\n",
    "    #Add Vegas lines\n",
    "    results = results.merge(\n",
    "        vegas_lines,\n",
    "        left_on='game_id',\n",
    "        right_on='game_id',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Save predictions\n",
    "    results.to_csv('../data/latest_predictions.csv', index=False)\n",
    "    print(\" Predictions saved to outputs/latest_predictions.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(week_games) > 0:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"PREDICTIONS FOR WEEK {current_week}, {current_season}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    for _, row in results.iterrows():\n",
    "        print(f\" {row['matchup']}\")\n",
    "        print(f\"   Game Date: {row['game_date']}\")\n",
    "        print(f\"   Home Win Probability: {row['home_win_prob']:.1%}\")\n",
    "        print(f\"   Away Win Probability: {row['away_win_prob']:.1%}\")\n",
    "        print(f\"    Predicted Winner: {row['predicted_winner']} ({row['confidence']:.1%} confidence)\")\n",
    "        print()\n",
    "    \n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Display as table\n",
    "    display(results[['matchup', 'game_date', 'home_win_prob', 'predicted_winner', 'confidence', 'home_moneyline', 'away_moneyline']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## 10. Visualize Results\n",
    "\n",
    "\n",
    "\n",
    " Create a visualization showing win probabilities for each game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(week_games) > 0:\n",
    "    print(\"Creating visualization...\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, len(results) * 0.6 + 2))\n",
    "    \n",
    "    # Color bars based on home/away favorite\n",
    "    colors = ['#d32f2f' if p < 0.5 else '#388e3c' for p in results['home_win_prob']]\n",
    "    \n",
    "    # Create horizontal bar chart\n",
    "    bars = ax.barh(results['matchup'], results['home_win_prob'], color=colors, edgecolor='white', linewidth=2)\n",
    "    \n",
    "    # Add probability labels\n",
    "    for i, (prob, matchup) in enumerate(zip(results['home_win_prob'], results['matchup'])):\n",
    "        ax.text(prob + 0.02, i, f'{prob:.1%}', va='center', fontweight='bold', fontsize=11)\n",
    "    \n",
    "    # Add 50% reference line\n",
    "    ax.axvline(x=0.5, color='gray', linestyle='--', linewidth=2, alpha=0.5)\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_xlabel('Home Team Win Probability', fontsize=13, fontweight='bold')\n",
    "    ax.set_title(f'NFL Predictions - Week {current_week}, {current_season}', \n",
    "                 fontsize=15, fontweight='bold', pad=20)\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_xticks([0, 0.25, 0.5, 0.75, 1.0])\n",
    "    ax.set_xticklabels(['0%', '25%', '50%', '75%', '100%'])\n",
    "    ax.grid(axis='x', alpha=0.3, linestyle=':', linewidth=1)\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#388e3c', label='Home Favorite'),\n",
    "        Patch(facecolor='#d32f2f', label='Away Favorite')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../outputs/predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\" Visualization saved to outputs/predictions.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ---\n",
    "\n",
    " ## Summary\n",
    "\n",
    "\n",
    "\n",
    " ### Model Performance\n",
    "\n",
    " - Training Accuracy: ~80-82%\n",
    "\n",
    " - Testing Accuracy: ~80-82%\n",
    "\n",
    "\n",
    "\n",
    " ### Key Features (Top 3)\n",
    "\n",
    " 1. Completion Percentage Differential\n",
    "\n",
    " 2. Passing TDs Differential\n",
    "\n",
    " 3. Rushing TDs Differential\n",
    "\n",
    "\n",
    "\n",
    " ### Files Created\n",
    "\n",
    " - `data/df_clean.csv` - Processed team statistics\n",
    "\n",
    " - `data/games_with_stats.csv` - Games with merged features\n",
    "\n",
    " - `data/most_recent_stats.csv` - Latest team stats\n",
    "\n",
    " - `models/finalized_model.pkl` - Trained model\n",
    "\n",
    " - `models/scaler.pkl` - Feature scaler\n",
    "\n",
    " - `models/feature_list.pkl` - Selected features\n",
    "\n",
    " - `outputs/feature_importance.png` - Feature importance chart\n",
    "\n",
    " - `outputs/predictions.png` - Predictions visualization\n",
    "\n",
    " - `outputs/latest_predictions.csv` - Current week predictions\n",
    "\n",
    "\n",
    "\n",
    " ### Next Steps\n",
    "\n",
    " - Run `streamlit run app.py` to view interactive predictions\n",
    "\n",
    " - Retrain model weekly as new games are played\n",
    "\n",
    " - Consider adding weather, injuries, or home field advantage features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nfl_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
